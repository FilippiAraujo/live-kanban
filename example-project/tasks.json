{
  "backlog": [
    {
      "id": "t1002",
      "descricao": "ter um botao de \"setup no projeto\", onde a gente pega um projeto que n√£o usa e inclui esse setup de pastas e etc - idealmente, a gente tem um agente acoplado que le o projeto e faz o objetivo e status tb",
      "detalhes": ""
    },
    {
      "id": "t1003",
      "descricao": "dentro das tasks, precisamos ter os \"to-do\", pra caso o agente n√£o finalize nessa sess√£o, ficou claro oq foi feito e o que precis fazer ainda pro proximo agente"
    },
    {
      "id": "t1004",
      "descricao": "ter um agente que √© capaz de, baseado na task atual, criar um prompt pro agente ir fazendo - tipo, voc√™ clica na task, ele vai ler o titulo e tudo mais, vai ler o conteudo, e, baseado nisso, nos objetivos status e mais, ele vai criar um prompt pra voc√™ \"continuar\" essa task"
    },
    {
      "id": "t1005",
      "descricao": "o \"objetivos e status\" precisa ser o cora√ß√£o do projeto, e, sempre que tiver uma altera√ß√£o, ou uma task nova, ele precisa ser atualizado, idealmente, temos um agente olhando para as altera√ß√µes futuras pos o dia daquele documento, que pega o que foi alterado, e atualiza o \"obejtivo e status\" ou algo similar, em uma linguagem que uma LLM entenda - pensa em como fazer isso"
    },
    {
      "id": "t1008",
      "descricao": "ter um \"LTS\" de boas praticas, pro agente sempre seguir e ver se esta seguindo, tipo, quando for react, usar a estrutura tal, pattern tal, etc.. se for usar postgres, mesma coisa, etc.. podemos ter uma aba com \"patterns\", onde a gente puxa automaticamente, baseado na tecnolgia, patterns e etc pro agente seguir, pra ser a \"regra\" do proejto - node, ddd, etc, sabe..."
    },
    {
      "id": "t1009",
      "descricao": "precisamos ter uma estrutura de agentes, usando um pouco da t1005, onde temos um agente olha do pra tudo pra atualizar as coisas, um (pra esse projeto em especial), precisa ter um agente que vai olhar pra ca e manter esse guia llm atualizado",
      "detalhes": ""
    },
    {
      "id": "t1010",
      "descricao": "ter op√ß√£o de, ao criar uma task nova, pedir pro agente deixar ela mais \"estruturada\", onde ele pega mais contexto sobre o projeto e tals, ele meio que \"LLMiza\" o textinho da task, pra ficar melhor, sabe?"
    },
    {
      "id": "t9513",
      "descricao": "testeee",
      "detalhes": "saassasaas"
    },
    {
      "id": "t4748",
      "descricao": "incluir mastra como agente, para orquestrar as coisas que precisam se algum tipo de agente"
    },
    {
      "id": "t7391",
      "descricao": "ao copiar um projeto (o path), idealmente, a gente copia junto, a explica√ß√£o do projeto, que vai ta la no objetivo e status, algo assim"
    }
  ],
  "todo": [
    {
      "id": "t8119",
      "descricao": "Em todas as paginas, tem um bot√£o de copiar e colocar a media de tokens que aquele texto que a pessoa ta copiando tem (ver como faz esse calculo de token)",
      "detalhes": "pagina sde objetivos e status precisa ter, e guia llm tb!\n\n\nO que s√£o tokens?\nOs tokens s√£o os blocos de constru√ß√£o do texto que os modelos da OpenAI processam. Eles podem ser t√£o curtos quanto um √∫nico caractere ou t√£o longos quanto uma palavra inteira, dependendo do idioma e do contexto. Espa√ßos, pontua√ß√£o e palavras parciais contribuem para a contagem de tokens. √â assim que a API segmenta internamente o seu texto antes de gerar uma resposta.\n\nRegras pr√°ticas √∫teis para o ingl√™s:\n\n1 token ‚âà 4 caracteres\n\n1 token ‚âà ¬æ de uma palavra\n\n100 tokens ‚âà 75 palavras\n\n1‚Äì2 frases ‚âà 30 tokens\n\n1 par√°grafo ‚âà 100 tokens\n\nAproximadamente 1.500 palavras ‚âà 2.048 tokens\n\nA tokeniza√ß√£o pode variar de acordo com o idioma. Por exemplo, ‚ÄúC√≥mo est√°s‚Äù (em espanhol, ‚ÄúComo voc√™ est√°?‚Äù) cont√©m 5 tokens para 10 caracteres. Textos em outros idiomas geralmente apresentam uma propor√ß√£o maior de tokens por caractere, o que pode afetar custos e limites.\n\nExemplos\nAqui est√£o alguns exemplos de texto do mundo real com suas contagens aproximadas de tokens:\n\nA frase de Wayne Gretzky \"Voc√™ perde 100% dos chutes que n√£o d√°\" = 11 fichas\n\nA Carta da OpenAI = 476 tokens\n\nA Declara√ß√£o de Independ√™ncia dos EUA = 1.695 fichas\n\nComo a contagem de tokens √© calculada\nAo enviar texto para a API:\n\nO texto est√° dividido em tokens.\n\nO modelo processa esses tokens.\n\nA resposta √© gerada como uma sequ√™ncia de tokens e, em seguida, convertida novamente em texto.\n\nO uso de tokens √© monitorado em diversas categorias:\n\nTokens de entrada ‚Äì tokens em sua solicita√ß√£o.\n\nTokens de sa√≠da ‚Äì tokens gerados na resposta.\n\nTokens em cache ‚Äì tokens reutilizados no hist√≥rico da conversa (geralmente cobrados a uma taxa reduzida).\n\nTokens de racioc√≠nio ‚Äì em alguns modelos avan√ßados, ‚Äúetapas de racioc√≠nio‚Äù adicionais s√£o inclu√≠das internamente antes de produzir o resultado final.\n\nEssas contagens aparecem nos metadados da sua resposta da API e s√£o usadas para faturamento e rastreamento de uso.\n\nPara explorar ainda mais a tokeniza√ß√£o, voc√™ pode usar nossa ferramenta interativa Tokenizer , que permite calcular o n√∫mero de tokens e ver como o texto √© dividido em tokens.\nAlternativamente\n, se preferir tokenizar o texto programaticamente, use o Tiktoken , um tokenizador BPE r√°pido, desenvolvido especificamente para modelos da OpenAI.\n\nLimites de tokens\nCada modelo possui um limite m√°ximo combinado de tokens (entrada + sa√≠da). Os modelos de alta capacidade atuais suportam at√© centenas de milhares de tokens em contexto, embora os limites pr√°ticos possam variar dependendo da vers√£o do modelo e do seu plano de uso.\n\nSe voc√™ ultrapassar o limite, poder√°:\n\nResumir ou reformular as perguntas.\n\nDivida textos longos em partes menores.\n\nResumir ou pr√©-processar as entradas antes de envi√°-las.\n\nPrecifica√ß√£o de tokens\nO uso da API √© cobrado por token, variando de acordo com o modelo e se os tokens s√£o de entrada, sa√≠da ou armazenados em cache. Consulte a p√°gina de pre√ßos da OpenAI para obter as taxas atuais. Alguns modelos de racioc√≠nio podem usar mais tokens internamente, mas visam melhorar a efici√™ncia reduzindo o n√∫mero de tokens necess√°rios por tarefa conclu√≠da.\n\nExplorando tokens\nA API trata as palavras de acordo com seu contexto nos dados do corpus. Os modelos recebem a solicita√ß√£o, convertem a entrada em uma lista de tokens, processam a solicita√ß√£o e convertem os tokens previstos de volta para as palavras que vemos na resposta.\n\nO que para n√≥s pode parecer duas palavras id√™nticas pode ser gerado em tokens diferentes, dependendo de como elas est√£o estruturadas no texto. Considere como a API gera valores de token para a palavra ' vermelho ' com base em seu contexto no texto:\n\n\n\nNo primeiro exemplo acima, o token ‚Äú2266‚Äù para 'vermelho' inclui um espa√ßo em branco no final (Observa√ß√£o: estes s√£o IDs de token de exemplo para fins de demonstra√ß√£o).\n\n\n\nO token ‚Äú2296‚Äù para 'Vermelho' (com um espa√ßo inicial e come√ßando com letra mai√∫scula) √© diferente do token ‚Äú2266‚Äù para 'vermelho' com letra min√∫scula.\n\n\n\nQuando 'Vermelho' √© usado no in√≠cio de uma frase, o token gerado n√£o inclui um espa√ßo inicial. O token ‚Äú7738‚Äù √© diferente dos dois exemplos anteriores da palavra.\n\nObserva√ß√µes:\nQuanto mais prov√°vel/frequente for um token, menor ser√° o n√∫mero atribu√≠do a ele:\n\nO token gerado para o ponto final √© o mesmo (‚Äú13‚Äù) nas tr√™s frases. Isso ocorre porque, contextualmente, o ponto final √© usado de maneira bastante semelhante em todo o conjunto de dados.\n\nO token gerado para 'vermelho' varia dependendo de sua posi√ß√£o na frase:\n\nMin√∫sculas no meio de uma frase: 'vermelho' - (token: ‚Äú2266‚Äù)\n\nLetra mai√∫scula no meio de uma frase: 'Vermelho' - (token: ‚Äú2297‚Äù)\n\nLetra mai√∫scula no in√≠cio de uma frase: 'Vermelho' - (token: ‚Äú7738‚Äù)"
    }
  ],
  "doing": [],
  "done": [
    {
      "id": "t1001",
      "descricao": "em obj e status ter um documento vivo que explique toda a stack, como o projeto funciona e mais, para que a LLM possa consultar e entender o core da aplica√ß√£o",
      "detalhes": "## O que era pra ser feito:\n- Criar documento que explique stack completa\n- Incluir arquitetura do projeto\n- Detalhar tecnologias usadas\n- Explicar como o projeto funciona\n- Servir como refer√™ncia para LLMs\n\n## O que foi feito:\n‚úÖ Criado arquivo `projeto-context.md` com 18 se√ß√µes completas\n‚úÖ Documentada stack completa (React 19, Tailwind v4, shadcn/ui, etc.)\n‚úÖ Inclu√≠da estrutura de pastas e arquivos\n‚úÖ Adicionadas regras de neg√≥cio e padr√µes de c√≥digo\n‚úÖ Documentados pontos cr√≠ticos de aten√ß√£o\n‚úÖ Explicadas decis√µes arquiteturais\n‚úÖ Adicionados exemplos de c√≥digo\n‚úÖ Inclu√≠do roadmap e pr√≥ximos passos\n‚úÖ Atualizado `llm-guide.md` para referenciar o novo arquivo\n\n## Arquivos criados/modificados:\n- example-project/projeto-context.md - NOVO arquivo com contexto completo\n- example-project/llm-guide.md - adicionada se√ß√£o 0 referenciando projeto-context.md"
    },
    {
      "id": "t1007",
      "descricao": "usar shadcn - precisamos ter um backlog tb"
    },
    {
      "id": "t1006",
      "descricao": "os cards devem ser editaveis e, dentro deles, ter o texto de \"o que ta sendo feito e como\" - isso deve ser um padrao tb, no guia da LLM, pra gente seguir um padr√£o - cada task precisa ter um botaozinho de copiar, que copia o path pra ela tb!",
      "detalhes": "## O que era pra ser feito:\n- Cards edit√°veis com campo de detalhes\n- Campo para descrever \"o que est√° sendo feito e como\"\n- Bot√£o de copiar que copia o path completo da task\n- Estabelecer padr√£o para guia LLM\n\n## O que foi feito:\n‚úÖ Atualizado tipo Task para incluir campo opcional 'detalhes'\n‚úÖ Implementado UI expand√≠vel nos cards (bot√£o \"+ Adicionar detalhes\")\n‚úÖ Edi√ß√£o inline com textarea para detalhes\n‚úÖ Bot√£o üìã que copia path completo: /path/to/project/tasks.json#taskId\n‚úÖ Adicionado Sonner (toast) para feedback visual ao copiar\n‚úÖ Cursor pointer no bot√£o de copiar\n‚úÖ Desabilita drag quando est√° editando\n‚úÖ Double-click para editar descri√ß√£o e detalhes\n\n## Arquivos modificados:\n- client/src/types.ts - adicionado campo detalhes\n- client/src/components/TaskCard.tsx - UI expand√≠vel e bot√£o copiar\n- client/src/components/KanbanColumn.tsx - passa projectPath\n- client/src/components/KanbanBoard.tsx - handleUpdateTask gen√©rico\n- client/src/App.tsx - adicionado Toaster"
    }
  ]
}